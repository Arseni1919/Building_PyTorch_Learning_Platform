# PyTorch Mastery Course - Requirements
# Python 3.9+ recommended
# Updated: October 2025

# Core Deep Learning Framework
torch>=2.5.0              # PyTorch with FlexAttention, torch.compile improvements
torchvision>=0.20.0       # Vision utilities and pretrained models
torchaudio>=2.5.0         # Audio processing (optional)

# Numerical Computing
numpy>=1.24.0             # Numerical operations
scipy>=1.11.0             # Scientific computing

# Data Processing
pandas>=2.0.0             # Data manipulation and analysis

# Visualization
matplotlib>=3.7.0         # Plotting and visualization
seaborn>=0.12.0           # Statistical visualizations
plotly>=5.17.0            # Interactive plots (optional)

# Jupyter Environment
jupyter>=1.0.0            # Jupyter notebook
jupyterlab>=4.0.0         # JupyterLab interface (optional)
ipywidgets>=8.1.0         # Interactive widgets

# Progress Bars
tqdm>=4.66.0              # Progress bars for loops

# Image Processing
Pillow>=10.0.0            # Image manipulation
opencv-python>=4.8.0      # Computer vision (optional)

# Natural Language Processing
transformers>=4.35.0      # HuggingFace transformers (for examples)
tokenizers>=0.15.0        # Fast tokenizers

# Model Optimization
onnx>=1.15.0              # ONNX export
onnxruntime>=1.16.0       # ONNX runtime

# Configuration Management
pyyaml>=6.0               # YAML configuration files
omegaconf>=2.3.0          # Hierarchical configuration (optional)

# Experiment Tracking (optional)
tensorboard>=2.15.0       # TensorBoard logging
wandb>=0.16.0             # Weights & Biases (optional)

# Testing and Quality
pytest>=7.4.0             # Unit testing (optional)
black>=23.10.0            # Code formatting (optional)

# Performance Profiling
py-cpuinfo>=9.0.0         # CPU information
psutil>=5.9.0             # System monitoring

# Additional Utilities
requests>=2.31.0          # HTTP requests
python-dotenv>=1.0.0      # Environment variables

# Optional: Accelerated Attention (if available)
# flash-attn>=2.5.0       # Flash Attention 2 (requires CUDA, compile from source)
# xformers>=0.0.23        # Memory-efficient attention (optional)

# Note: For Flash Attention and other CUDA-specific packages:
# - Ensure you have compatible CUDA version (11.8+ or 12.1+)
# - May need to install from source or use pre-built wheels
# - See: https://github.com/Dao-AILab/flash-attention

# Installation Instructions:
# 1. Create virtual environment: python -m venv venv
# 2. Activate: source venv/bin/activate (Linux/Mac) or venv\Scripts\activate (Windows)
# 3. Install PyTorch with CUDA (check https://pytorch.org for your CUDA version):
#    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
# 4. Install remaining packages: pip install -r requirements.txt
