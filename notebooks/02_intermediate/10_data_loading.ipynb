{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 10: Advanced Data Loading & Augmentation\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand **why** efficient data loading is critical for training\n",
    "- Master PyTorch's `Dataset` and `DataLoader` classes\n",
    "- Build custom datasets for various data types\n",
    "- Implement data augmentation strategies\n",
    "- Optimize data loading with multiprocessing and prefetching\n",
    "- Handle common data loading challenges\n",
    "- Connect data loading to model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Picture: Why Data Loading Matters\n",
    "\n",
    "### The Training Bottleneck\n",
    "\n",
    "**Training loop**:\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:  # ← THIS is often the bottleneck!\n",
    "        loss = model(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "**Common problem**: GPU sits idle waiting for data!\n",
    "\n",
    "```\n",
    "Bad data loading:\n",
    "CPU: [Load]     [Load]     [Load]     [Load]\n",
    "GPU:        [Train] [Idle] [Train] [Idle] [Train]\n",
    "         ↑ GPU waiting for data!\n",
    "\n",
    "Good data loading:\n",
    "CPU: [Load][Load][Load][Load][Load][Load]\n",
    "GPU: [Train][Train][Train][Train][Train]\n",
    "         ↑ GPU always busy!\n",
    "```\n",
    "\n",
    "**Why this matters**:\n",
    "- **Cost**: GPU time is expensive (A100: $1-4/hour)\n",
    "- **Training time**: Can be 2-10x slower with bad data loading\n",
    "- **Model quality**: More iterations = better models\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "**Example**: Training ImageNet (1.3M images)\n",
    "- **Naive loading**: Read from disk every epoch = ~3 hours per epoch\n",
    "- **Optimized loading**: Prefetch + cache + augmentation = ~30 min per epoch\n",
    "- **Savings**: 6x faster = 6x more experiments!\n",
    "\n",
    "**Why it cannot be skipped**: Efficient data loading is the difference between:\n",
    "- Research that takes weeks vs days\n",
    "- Models that train to completion vs OOM errors\n",
    "- Affordable experimentation vs prohibitive costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2  # New API (PyTorch 2.0+)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Data Loading: The Foundation\n",
    "\n",
    "### Core Components\n",
    "\n",
    "**1. `Dataset`**: Represents your data\n",
    "- Abstract class with `__len__` and `__getitem__`\n",
    "- Defines how to access individual samples\n",
    "\n",
    "**2. `DataLoader`**: Loads data in batches\n",
    "- Batching, shuffling, parallel loading\n",
    "- Handles multiprocessing and prefetching\n",
    "\n",
    "**3. `Sampler`**: Controls sampling strategy\n",
    "- Sequential, random, weighted, distributed\n",
    "\n",
    "**4. `Transforms`**: Data preprocessing and augmentation\n",
    "- Resize, normalize, augment\n",
    "\n",
    "### The Data Flow\n",
    "\n",
    "```\n",
    "Dataset → Sampler → DataLoader → Model\n",
    "   ↓         ↓          ↓\n",
    "  Access   Order    Batching\n",
    "  data     samples  + parallel\n",
    "```\n",
    "\n",
    "### Why This Design?\n",
    "\n",
    "**Separation of concerns**:\n",
    "- **Dataset**: What data to load (logic)\n",
    "- **Sampler**: Which samples to load (order)\n",
    "- **DataLoader**: How to load (parallelism, batching)\n",
    "\n",
    "**Benefits**:\n",
    "- Modular and reusable\n",
    "- Easy to customize each part\n",
    "- Efficient parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Custom Datasets\n",
    "\n",
    "### The Minimal Dataset\n",
    "\n",
    "Every dataset needs:\n",
    "1. `__init__`: Initialize (load file paths, metadata, etc.)\n",
    "2. `__len__`: Return number of samples\n",
    "3. `__getitem__`: Return one sample given an index\n",
    "\n",
    "**Why this interface?**\n",
    "- `__len__`: DataLoader needs to know how many samples\n",
    "- `__getitem__`: Allows indexing like `dataset[0]`\n",
    "- Simple contract enables powerful functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Minimal custom dataset example.\n",
    "    \n",
    "    Demonstrates the required interface.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: Input data (can be paths, arrays, etc.)\n",
    "            labels: Corresponding labels\n",
    "            transform: Optional transform function\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples.\"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load and return a single sample.\n",
    "        \n",
    "        Args:\n",
    "            idx: Index of the sample to retrieve\n",
    "        \n",
    "        Returns:\n",
    "            (sample, label) tuple\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply transform if provided\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "# Test the dataset\n",
    "data = torch.randn(100, 3, 32, 32)  # 100 samples, 3 channels, 32x32\n",
    "labels = torch.randint(0, 10, (100,))  # 10 classes\n",
    "\n",
    "dataset = SimpleDataset(data, labels)\n",
    "\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"First sample shape: {dataset[0][0].shape}\")\n",
    "print(f\"First label: {dataset[0][1]}\")\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Iterate\n",
    "for batch_idx, (samples, labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx}: samples {samples.shape}, labels {labels.shape}\")\n",
    "    if batch_idx == 2:  # Just show first 3 batches\n",
    "        break\n",
    "\n",
    "print(\"\\nDataset + DataLoader: ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Dataset: Image Classification from Disk\n",
    "\n",
    "### Common Pattern: Load Images from Directory\n",
    "\n",
    "**Directory structure**:\n",
    "```\n",
    "dataset/\n",
    "  class_0/\n",
    "    img1.jpg\n",
    "    img2.jpg\n",
    "  class_1/\n",
    "    img3.jpg\n",
    "    img4.jpg\n",
    "```\n",
    "\n",
    "**Why this pattern?**\n",
    "- **Memory efficient**: Don't load all images at once\n",
    "- **Flexible**: Easy to add/remove samples\n",
    "- **Standard**: Most datasets organized this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load images from a directory structure.\n",
    "    \n",
    "    Expected structure:\n",
    "      root/\n",
    "        class_0/\n",
    "          img1.jpg\n",
    "        class_1/\n",
    "          img2.jpg\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Root directory path\n",
    "            transform: Optional transform to apply\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Find all images and create class mapping\n",
    "        self.samples = []  # List of (image_path, class_idx)\n",
    "        self.classes = []  # List of class names\n",
    "        self.class_to_idx = {}  # Map class name to index\n",
    "        \n",
    "        # Scan directory\n",
    "        self._scan_directory()\n",
    "    \n",
    "    def _scan_directory(self):\n",
    "        \"\"\"Scan directory and build sample list.\"\"\"\n",
    "        # Get all class directories\n",
    "        class_dirs = sorted([d for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        for class_idx, class_dir in enumerate(class_dirs):\n",
    "            class_name = class_dir.name\n",
    "            self.classes.append(class_name)\n",
    "            self.class_to_idx[class_name] = class_idx\n",
    "            \n",
    "            # Find all images in this class\n",
    "            for img_path in class_dir.glob('*.jpg'):  # Or *.png, *.jpeg, etc.\n",
    "                self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Load and return a sample.\"\"\"\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        # Why here? Lazy loading - only load when needed\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "print(\"ImageFolderDataset: ✓\")\n",
    "print(\"\\nNote: This is similar to torchvision.datasets.ImageFolder\")\n",
    "print(\"Building your own helps understand the internals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation: Creating More Data\n",
    "\n",
    "### Why Augmentation?\n",
    "\n",
    "**Problem**: Limited training data leads to overfitting\n",
    "\n",
    "**Solution**: Generate variations of existing data\n",
    "\n",
    "**Benefits**:\n",
    "1. **More training data**: \"Free\" samples from existing ones\n",
    "2. **Better generalization**: Model sees more variations\n",
    "3. **Robustness**: Model learns invariances (rotation, brightness, etc.)\n",
    "4. **Regularization**: Prevents overfitting\n",
    "\n",
    "**Why it works**:\n",
    "- Real-world data has natural variations\n",
    "- Augmentation simulates these variations\n",
    "- Model learns to be invariant to irrelevant changes\n",
    "\n",
    "### Common Image Augmentations\n",
    "\n",
    "**Geometric**:\n",
    "- Random crop, resize, flip, rotate\n",
    "- Why? Objects appear at different positions/scales/orientations\n",
    "\n",
    "**Color**:\n",
    "- Brightness, contrast, saturation, hue\n",
    "- Why? Lighting conditions vary\n",
    "\n",
    "**Modern (advanced)**:\n",
    "- Cutout, Mixup, CutMix, AutoAugment\n",
    "- Why? Further improve generalization\n",
    "\n",
    "### When to Apply Augmentation?\n",
    "\n",
    "**Training**: Apply random augmentations\n",
    "- Each epoch sees different variations\n",
    "- Creates effectively infinite dataset\n",
    "\n",
    "**Validation/Test**: NO augmentation (or minimal)\n",
    "- Need consistent evaluation\n",
    "- Only apply necessary preprocessing (resize, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipelines\n",
    "\n",
    "# Training: Heavy augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Random crop and resize\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of flipping\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation: Minimal preprocessing only\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize to slightly larger\n",
    "    transforms.CenterCrop(224),  # Center crop to target size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data Augmentation Pipelines:\")\n",
    "print(\"\\nTraining pipeline:\")\n",
    "for i, t in enumerate(train_transform.transforms):\n",
    "    print(f\"  {i+1}. {t.__class__.__name__}\")\n",
    "\n",
    "print(\"\\nValidation pipeline:\")\n",
    "for i, t in enumerate(val_transform.transforms):\n",
    "    print(f\"  {i+1}. {t.__class__.__name__}\")\n",
    "\n",
    "print(\"\\nKey differences:\")\n",
    "print(\"✓ Training: Random crops, flips, color jitter, rotation\")\n",
    "print(\"✓ Validation: Deterministic resize and center crop only\")\n",
    "print(\"✓ Both: Normalize with same statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Augmentations\n",
    "\n",
    "Let's see what augmentations actually do to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 for demonstration\n",
    "cifar_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                               download=True, transform=None)\n",
    "\n",
    "# Get one image\n",
    "original_img, label = cifar_dataset[0]\n",
    "\n",
    "# Define augmentation (without normalization for visualization)\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "])\n",
    "\n",
    "# Apply augmentation multiple times\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Show original\n",
    "axes[0].imshow(original_img)\n",
    "axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Show augmented versions\n",
    "for i in range(1, 8):\n",
    "    augmented = augmentation(original_img)\n",
    "    axes[i].imshow(augmented)\n",
    "    axes[i].set_title(f'Augmented {i}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation: Same Image, Different Views', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Each augmented version is slightly different!\")\n",
    "print(\"During training, the model sees new variations every epoch.\")\n",
    "print(\"This forces the model to learn robust features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing DataLoader Performance\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "**1. `num_workers`**: Number of subprocesses for data loading\n",
    "- **Why?** Parallel loading while GPU trains\n",
    "- **Optimal**: Usually 4-8 (depends on CPU cores)\n",
    "- **Too many**: Overhead from process creation\n",
    "\n",
    "**2. `batch_size`**: Samples per batch\n",
    "- **Why?** Trade-off: memory vs convergence\n",
    "- **Larger**: Faster (better GPU utilization), but more memory\n",
    "- **Smaller**: More updates, but slower\n",
    "\n",
    "**3. `shuffle`**: Randomize order\n",
    "- **Training**: True (prevents overfitting to order)\n",
    "- **Validation/Test**: False (reproducible evaluation)\n",
    "\n",
    "**4. `pin_memory`**: Pin memory for GPU transfer\n",
    "- **Why?** Faster CPU→GPU transfer\n",
    "- **When**: Always True if using GPU\n",
    "\n",
    "**5. `prefetch_factor`**: Batches to prefetch per worker\n",
    "- **Why?** Keep GPU fed\n",
    "- **Default**: 2 (usually good)\n",
    "\n",
    "**6. `persistent_workers`**: Keep workers alive between epochs\n",
    "- **Why?** Avoid worker restart overhead\n",
    "- **When**: True for faster training (PyTorch 1.7+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# Compare different configurations\n",
    "configs = [\n",
    "    {'name': 'Slow (no parallelism)', 'num_workers': 0, 'pin_memory': False},\n",
    "    {'name': 'Fast (optimized)', 'num_workers': 4, 'pin_memory': True, 'persistent_workers': True},\n",
    "]\n",
    "\n",
    "print(\"Comparing DataLoader Configurations:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for config in configs:\n",
    "    name = config.pop('name')\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=128, shuffle=True, **config)\n",
    "    \n",
    "    # Time one epoch\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        # Simulate some processing\n",
    "        _ = data.mean()\n",
    "        if batch_idx >= 50:  # Just test first 50 batches\n",
    "            break\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"  Time for 50 batches: {elapsed:.2f}s\")\n",
    "    print(f\"  Configuration: {config}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nKey takeaway: Parallel workers + pin_memory = much faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices Summary\n",
    "\n",
    "**For training on GPU**:\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,        # As large as GPU memory allows\n",
    "    shuffle=True,         # Randomize order\n",
    "    num_workers=4,        # 4-8 workers (depends on CPU)\n",
    "    pin_memory=True,      # Faster GPU transfer\n",
    "    persistent_workers=True,  # Keep workers alive\n",
    "    prefetch_factor=2,    # Prefetch 2 batches per worker\n",
    ")\n",
    "```\n",
    "\n",
    "**For validation/test**:\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,       # Can be larger (no backprop)\n",
    "    shuffle=False,        # Deterministic evaluation\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Weighted Sampling for Imbalanced Data\n",
    "\n",
    "### The Problem\n",
    "\n",
    "**Imbalanced dataset**:\n",
    "```\n",
    "Class 0: 900 samples\n",
    "Class 1: 100 samples\n",
    "```\n",
    "\n",
    "**Issue**: Model sees class 0 much more → biased predictions\n",
    "\n",
    "### Solutions\n",
    "\n",
    "**1. Weighted Loss**:\n",
    "```python\n",
    "weights = [0.1, 0.9]  # Higher weight for rare class\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights))\n",
    "```\n",
    "\n",
    "**2. Weighted Sampling**: Sample classes equally\n",
    "```python\n",
    "sampler = WeightedRandomSampler(weights, num_samples)\n",
    "```\n",
    "\n",
    "**Why sampling?**\n",
    "- Model sees balanced batches\n",
    "- Learns all classes equally\n",
    "- No need to modify loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Create imbalanced dataset\n",
    "class_counts = [900, 100]  # Class 0 has 900, class 1 has 100\n",
    "labels = [0] * 900 + [1] * 100\n",
    "data = torch.randn(1000, 3, 32, 32)\n",
    "\n",
    "imbalanced_dataset = SimpleDataset(data, torch.tensor(labels))\n",
    "\n",
    "# Compute sample weights (inverse of class frequency)\n",
    "class_sample_counts = torch.tensor(class_counts)\n",
    "class_weights = 1.0 / class_sample_counts\n",
    "\n",
    "# Assign weight to each sample based on its class\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "# Create sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True  # Sample with replacement\n",
    ")\n",
    "\n",
    "# Create dataloader with sampler\n",
    "balanced_loader = DataLoader(imbalanced_dataset, batch_size=64, sampler=sampler)\n",
    "\n",
    "# Check class distribution in batches\n",
    "class_counts_in_batches = [0, 0]\n",
    "num_batches = 10\n",
    "\n",
    "for batch_idx, (_, labels_batch) in enumerate(balanced_loader):\n",
    "    for label in labels_batch:\n",
    "        class_counts_in_batches[label.item()] += 1\n",
    "    \n",
    "    if batch_idx >= num_batches - 1:\n",
    "        break\n",
    "\n",
    "print(\"Imbalanced Dataset:\")\n",
    "print(f\"  Class 0: {class_counts[0]} samples\")\n",
    "print(f\"  Class 1: {class_counts[1]} samples\")\n",
    "print(f\"  Ratio: {class_counts[0]/class_counts[1]:.1f}:1\\n\")\n",
    "\n",
    "print(f\"After Weighted Sampling (first {num_batches} batches):\")\n",
    "print(f\"  Class 0: {class_counts_in_batches[0]} samples\")\n",
    "print(f\"  Class 1: {class_counts_in_batches[1]} samples\")\n",
    "print(f\"  Ratio: {class_counts_in_batches[0]/class_counts_in_batches[1]:.1f}:1\")\n",
    "\n",
    "print(\"\\n✓ Classes are now balanced in training batches!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Build a Text Dataset\n",
    "\n",
    "Create a dataset for text classification from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# SOLUTION\n",
    "def show_solution_1():\n",
    "    import pandas as pd\n",
    "    \n",
    "    class TextDataset(Dataset):\n",
    "        \"\"\"\n",
    "        Text classification dataset from CSV.\n",
    "        \n",
    "        CSV format: text, label\n",
    "        \"\"\"\n",
    "        def __init__(self, csv_file, tokenizer=None, max_len=128):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                csv_file: Path to CSV file\n",
    "                tokenizer: Function to tokenize text\n",
    "                max_len: Maximum sequence length\n",
    "            \"\"\"\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_len = max_len\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            text = self.df.iloc[idx]['text']\n",
    "            label = self.df.iloc[idx]['label']\n",
    "            \n",
    "            # Tokenize if tokenizer provided\n",
    "            if self.tokenizer:\n",
    "                tokens = self.tokenizer(text)\n",
    "                # Pad/truncate to max_len\n",
    "                if len(tokens) < self.max_len:\n",
    "                    tokens = tokens + [0] * (self.max_len - len(tokens))\n",
    "                else:\n",
    "                    tokens = tokens[:self.max_len]\n",
    "                return torch.tensor(tokens), label\n",
    "            \n",
    "            return text, label\n",
    "    \n",
    "    print(\"TextDataset implementation:\")\n",
    "    print(\"\\nKey features:\")\n",
    "    print(\"✓ Reads from CSV file\")\n",
    "    print(\"✓ Optional tokenization\")\n",
    "    print(\"✓ Padding/truncation to fixed length\")\n",
    "    print(\"\\nUsage:\")\n",
    "    print(\"  dataset = TextDataset('data.csv', tokenizer=my_tokenizer)\")\n",
    "    print(\"  loader = DataLoader(dataset, batch_size=32, shuffle=True)\")\n",
    "\n",
    "# Uncomment to see solution:\n",
    "# show_solution_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Custom Augmentation\n",
    "\n",
    "Create a custom transformation that adds Gaussian noise to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# SOLUTION\n",
    "def show_solution_2():\n",
    "    class AddGaussianNoise(object):\n",
    "        \"\"\"\n",
    "        Add Gaussian noise to tensor.\n",
    "        \n",
    "        Why? Simulates sensor noise, improves robustness.\n",
    "        \"\"\"\n",
    "        def __init__(self, mean=0.0, std=0.1):\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "        \n",
    "        def __call__(self, tensor):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tensor: Input tensor (C, H, W)\n",
    "            \n",
    "            Returns:\n",
    "                Tensor with added noise\n",
    "            \"\"\"\n",
    "            noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "            noisy_tensor = tensor + noise\n",
    "            # Clamp to valid range [0, 1]\n",
    "            return torch.clamp(noisy_tensor, 0.0, 1.0)\n",
    "        \n",
    "        def __repr__(self):\n",
    "            return f\"{self.__class__.__name__}(mean={self.mean}, std={self.std})\"\n",
    "    \n",
    "    # Test the augmentation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        AddGaussianNoise(mean=0.0, std=0.05)\n",
    "    ])\n",
    "    \n",
    "    # Load sample image\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=None)\n",
    "    img, _ = dataset[0]\n",
    "    \n",
    "    # Apply transformation\n",
    "    img_original = transforms.ToTensor()(img)\n",
    "    img_noisy = transform(img)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img_original.permute(1, 2, 0))\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(img_noisy.permute(1, 2, 0))\n",
    "    axes[1].set_title('With Gaussian Noise')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Custom augmentation: AddGaussianNoise\")\n",
    "    print(\"\\nWhy add noise?\")\n",
    "    print(\"- Simulates real-world sensor noise\")\n",
    "    print(\"- Improves model robustness\")\n",
    "    print(\"- Acts as regularization\")\n",
    "\n",
    "# Uncomment to see solution:\n",
    "# show_solution_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Implement Data Caching\n",
    "\n",
    "Create a dataset wrapper that caches loaded samples in memory for faster access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# SOLUTION\n",
    "def show_solution_3():\n",
    "    class CachedDataset(Dataset):\n",
    "        \"\"\"\n",
    "        Wrapper that caches dataset samples in memory.\n",
    "        \n",
    "        Trade-off: Speed vs Memory\n",
    "        - Faster: No repeated disk I/O\n",
    "        - Cost: Stores all samples in RAM\n",
    "        \n",
    "        Use when: Dataset fits in memory and I/O is bottleneck\n",
    "        \"\"\"\n",
    "        def __init__(self, dataset, cache_size=None):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                dataset: Underlying dataset to cache\n",
    "                cache_size: Max samples to cache (None = cache all)\n",
    "            \"\"\"\n",
    "            self.dataset = dataset\n",
    "            self.cache = {}\n",
    "            self.cache_size = cache_size or len(dataset)\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            # Check cache first\n",
    "            if idx in self.cache:\n",
    "                return self.cache[idx]\n",
    "            \n",
    "            # Load from dataset\n",
    "            sample = self.dataset[idx]\n",
    "            \n",
    "            # Cache if space available\n",
    "            if len(self.cache) < self.cache_size:\n",
    "                self.cache[idx] = sample\n",
    "            \n",
    "            return sample\n",
    "    \n",
    "    # Test caching\n",
    "    # Create base dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    base_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                                  download=True, transform=transform)\n",
    "    \n",
    "    # Create cached version\n",
    "    cached_dataset = CachedDataset(base_dataset, cache_size=1000)\n",
    "    \n",
    "    # Measure time for first access (cache miss)\n",
    "    start = time.time()\n",
    "    for i in range(100):\n",
    "        _ = cached_dataset[i]\n",
    "    first_access = time.time() - start\n",
    "    \n",
    "    # Measure time for second access (cache hit)\n",
    "    start = time.time()\n",
    "    for i in range(100):\n",
    "        _ = cached_dataset[i]\n",
    "    second_access = time.time() - start\n",
    "    \n",
    "    print(\"CachedDataset Performance:\")\n",
    "    print(f\"  First access (cache miss): {first_access:.3f}s\")\n",
    "    print(f\"  Second access (cache hit): {second_access:.3f}s\")\n",
    "    print(f\"  Speedup: {first_access/second_access:.1f}x\\n\")\n",
    "    \n",
    "    print(\"When to use caching:\")\n",
    "    print(\"✓ Dataset fits in RAM\")\n",
    "    print(\"✓ Disk I/O is bottleneck\")\n",
    "    print(\"✓ Multiple epochs over same data\")\n",
    "    print(\"\\nWhen NOT to use:\")\n",
    "    print(\"✗ Large datasets (won't fit in RAM)\")\n",
    "    print(\"✗ Heavy data augmentation (cache becomes stale)\")\n",
    "\n",
    "# Uncomment to see solution:\n",
    "# show_solution_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "**1. Why data loading matters**:\n",
    "- Often the training bottleneck\n",
    "- Poor data loading = GPU sits idle = wasted money\n",
    "- Good data loading = 2-10x faster training\n",
    "\n",
    "**2. PyTorch data loading pipeline**:\n",
    "- **Dataset**: Defines data access (`__len__`, `__getitem__`)\n",
    "- **DataLoader**: Batching, shuffling, parallel loading\n",
    "- **Transforms**: Preprocessing and augmentation\n",
    "- **Sampler**: Controls sampling strategy\n",
    "\n",
    "**3. Data augmentation**:\n",
    "- Creates variations of existing data\n",
    "- Improves generalization and robustness\n",
    "- **Training**: Heavy augmentation\n",
    "- **Validation/Test**: Minimal preprocessing only\n",
    "\n",
    "**4. Optimization techniques**:\n",
    "- **`num_workers`**: Parallel loading (4-8 workers)\n",
    "- **`pin_memory`**: Faster GPU transfer (always True)\n",
    "- **`persistent_workers`**: Avoid restart overhead\n",
    "- **Caching**: Trade memory for speed\n",
    "- **Weighted sampling**: Handle imbalanced data\n",
    "\n",
    "**5. Best practices**:\n",
    "- Lazy loading (load in `__getitem__`, not `__init__`)\n",
    "- Separate train/val transforms\n",
    "- Use multiple workers for large datasets\n",
    "- Monitor GPU utilization (should be near 100%)\n",
    "- Profile to find bottlenecks\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "**Image classification**:\n",
    "```python\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(...),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(...)\n",
    "])\n",
    "```\n",
    "\n",
    "**Efficient DataLoader**:\n",
    "```python\n",
    "DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "You've mastered data loading! This completes the intermediate section.\n",
    "\n",
    "**You now understand**:\n",
    "- CNNs and their evolution\n",
    "- Attention mechanisms (the foundation of transformers)\n",
    "- Positional encodings (injecting sequence information)\n",
    "- Complete transformer architecture\n",
    "- Efficient data loading and augmentation\n",
    "\n",
    "**Ready for advanced topics**:\n",
    "- Modern transformer variants (Flash Attention, GQA)\n",
    "- Training large models at scale\n",
    "- Building production-ready systems\n",
    "\n",
    "Congratulations on completing the intermediate section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "### PyTorch Documentation\n",
    "1. **Data Loading Tutorial**: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "2. **torch.utils.data API**: https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "### Data Augmentation\n",
    "3. **AutoAugment** (Cubuk et al., 2019): Learned augmentation policies\n",
    "4. **RandAugment** (Cubuk et al., 2020): Simplified AutoAugment\n",
    "5. **Mixup** (Zhang et al., 2017): Mix samples for training\n",
    "6. **CutMix** (Yun et al., 2019): Cut and paste regions\n",
    "\n",
    "### Advanced Techniques\n",
    "7. **FFCV** (Fast Forward Computer Vision): Ultra-fast data loading\n",
    "8. **WebDataset**: Efficient loading from cloud storage\n",
    "9. **NVIDIA DALI**: GPU-accelerated data loading\n",
    "\n",
    "### Tools\n",
    "- **albumentations**: Fast augmentation library\n",
    "- **torchvision.transforms.v2**: New transforms API\n",
    "- **kornia**: Differentiable augmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
