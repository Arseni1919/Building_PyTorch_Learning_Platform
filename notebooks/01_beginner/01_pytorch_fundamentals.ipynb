{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 1: PyTorch Fundamentals - Tensors & Operations\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand what tensors are and why they're fundamental to deep learning\n",
    "- Create and manipulate tensors using PyTorch\n",
    "- Perform mathematical operations on tensors\n",
    "- Understand tensor shapes, broadcasting, and reshaping\n",
    "- Know when to use PyTorch vs NumPy\n",
    "- Leverage GPU acceleration for computations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Big Picture: What Are Tensors?\n",
    "\n",
    "### Why Do We Need Tensors?\n",
    "\n",
    "Imagine you're building a model that recognizes images of cats and dogs. Each image is made up of thousands of pixels, and each pixel has RGB color values. How do you represent this data in code?\n",
    "\n",
    "- A **scalar** is a single number: `5` (0-dimensional)\n",
    "- A **vector** is a 1D array: `[1, 2, 3]` (1-dimensional)\n",
    "- A **matrix** is a 2D array: `[[1, 2], [3, 4]]` (2-dimensional)\n",
    "- A **tensor** is an n-dimensional array: can be 3D, 4D, 5D, etc.\n",
    "\n",
    "For our cat/dog image:\n",
    "- **3D tensor**: (height, width, RGB channels) → a single image\n",
    "- **4D tensor**: (batch_size, height, width, channels) → multiple images\n",
    "\n",
    "**Tensors are the universal data structure for deep learning** because they can represent any type of data and can be efficiently processed on GPUs.\n",
    "\n",
    "### Why PyTorch Tensors vs NumPy Arrays?\n",
    "\n",
    "NumPy is great, but PyTorch tensors offer:\n",
    "1. **GPU acceleration**: 100x faster computations\n",
    "2. **Automatic differentiation**: Calculate gradients automatically (essential for training)\n",
    "3. **Deep learning ecosystem**: Built-in neural network layers, optimizers, etc.\n",
    "\n",
    "Think of PyTorch as \"NumPy with superpowers for deep learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Creating Tensors\n",
    "\n",
    "Let's explore different ways to create tensors. Each method has its use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: From Python lists\n",
    "# Use case: Small, manually specified data\n",
    "scalar = torch.tensor(42)\n",
    "vector = torch.tensor([1, 2, 3, 4])\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "print(\"Scalar (0D):\", scalar)\n",
    "print(\"Shape:\", scalar.shape)  # torch.Size([]) - no dimensions\n",
    "print()\n",
    "\n",
    "print(\"Vector (1D):\", vector)\n",
    "print(\"Shape:\", vector.shape)  # torch.Size([4])\n",
    "print()\n",
    "\n",
    "print(\"Matrix (2D):\", matrix)\n",
    "print(\"Shape:\", matrix.shape)  # torch.Size([2, 3]) - 2 rows, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Special initialization functions\n",
    "# Use case: Initialize model parameters, create placeholders\n",
    "\n",
    "# All zeros (useful for initializing biases)\n",
    "zeros = torch.zeros(2, 3)\n",
    "print(\"Zeros:\\n\", zeros)\n",
    "print()\n",
    "\n",
    "# All ones\n",
    "ones = torch.ones(2, 3)\n",
    "print(\"Ones:\\n\", ones)\n",
    "print()\n",
    "\n",
    "# Random values from uniform distribution [0, 1)\n",
    "# Use case: Weight initialization (with proper scaling)\n",
    "rand_uniform = torch.rand(2, 3)\n",
    "print(\"Random uniform [0, 1):\\n\", rand_uniform)\n",
    "print()\n",
    "\n",
    "# Random values from standard normal distribution (mean=0, std=1)\n",
    "# Use case: Common weight initialization (Xavier, He initialization use this)\n",
    "rand_normal = torch.randn(2, 3)\n",
    "print(\"Random normal:\\n\", rand_normal)\n",
    "print()\n",
    "\n",
    "# Identity matrix (diagonal = 1, rest = 0)\n",
    "# Use case: Residual connections, specific initializations\n",
    "identity = torch.eye(3)\n",
    "print(\"Identity matrix:\\n\", identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: From NumPy arrays (common when working with data)\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"From NumPy:\\n\", tensor_from_numpy)\n",
    "print(\"Type:\", tensor_from_numpy.dtype)  # Note: int64 by default\n",
    "\n",
    "# Converting back to NumPy (shares memory - be careful!)\n",
    "back_to_numpy = tensor_from_numpy.numpy()\n",
    "print(\"\\nBack to NumPy:\\n\", back_to_numpy)\n",
    "\n",
    "# They share memory! Changing one affects the other\n",
    "tensor_from_numpy[0, 0] = 999\n",
    "print(\"\\nAfter modifying tensor:\")\n",
    "print(\"Tensor:\", tensor_from_numpy)\n",
    "print(\"NumPy:\", back_to_numpy)  # Also changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Does Shape Matter?\n",
    "\n",
    "**Shape is the most important concept in tensor programming.** Most bugs in deep learning code come from shape mismatches.\n",
    "\n",
    "Think of shape as the \"type system\" of tensors:\n",
    "- You can't add a `(2, 3)` tensor to a `(3, 2)` tensor directly\n",
    "- Neural network layers expect specific input shapes\n",
    "- Understanding shapes helps you design architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding tensor properties\n",
    "x = torch.randn(2, 3, 4)  # 3D tensor\n",
    "\n",
    "print(f\"Tensor:\\n{x}\")\n",
    "print(f\"\\nShape: {x.shape}\")        # torch.Size([2, 3, 4])\n",
    "print(f\"Size: {x.size()}\")          # Same as shape\n",
    "print(f\"Number of dimensions: {x.ndim}\")  # 3\n",
    "print(f\"Total number of elements: {x.numel()}\")  # 2 * 3 * 4 = 24\n",
    "print(f\"Data type: {x.dtype}\")     # torch.float32 (default for randn)\n",
    "print(f\"Device: {x.device}\")       # cpu or cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Types (dtype)\n",
    "\n",
    "### Why Do Data Types Matter?\n",
    "\n",
    "- **Memory**: `float32` uses 4 bytes, `float16` uses 2 bytes\n",
    "- **Speed**: GPUs are optimized for `float16` and `float32`\n",
    "- **Precision**: Training usually needs `float32`, inference can use `float16`\n",
    "- **Compatibility**: Some operations require specific types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common data types\n",
    "float32 = torch.tensor([1.0, 2.0], dtype=torch.float32)  # Default, most common\n",
    "float16 = torch.tensor([1.0, 2.0], dtype=torch.float16)  # Half precision (faster)\n",
    "int64 = torch.tensor([1, 2], dtype=torch.int64)          # Default for integers\n",
    "bool_tensor = torch.tensor([True, False], dtype=torch.bool)  # Boolean\n",
    "\n",
    "print(f\"float32: {float32.dtype}, size: {float32.element_size()} bytes per element\")\n",
    "print(f\"float16: {float16.dtype}, size: {float16.element_size()} bytes per element\")\n",
    "print(f\"int64: {int64.dtype}, size: {int64.element_size()} bytes per element\")\n",
    "print(f\"bool: {bool_tensor.dtype}, size: {bool_tensor.element_size()} bytes per element\")\n",
    "\n",
    "# Converting between types\n",
    "x = torch.tensor([1.5, 2.5, 3.5])\n",
    "print(f\"\\nOriginal: {x}, dtype: {x.dtype}\")\n",
    "print(f\"To int: {x.int()}, dtype: {x.int().dtype}\")  # Truncates!\n",
    "print(f\"To long (int64): {x.long()}, dtype: {x.long().dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Tensor Operations\n",
    "\n",
    "### Mathematical Operations\n",
    "\n",
    "PyTorch provides two ways to do operations:\n",
    "1. **Functions**: `torch.add(a, b)`\n",
    "2. **Methods**: `a.add(b)`\n",
    "3. **Operators**: `a + b`\n",
    "\n",
    "They're all equivalent! Use what's most readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise operations (operate on each element individually)\n",
    "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# Addition\n",
    "print(\"Addition (a + b):\")\n",
    "print(a + b)  # [[6, 8], [10, 12]]\n",
    "print()\n",
    "\n",
    "# Element-wise multiplication (NOT matrix multiplication!)\n",
    "print(\"Element-wise multiplication (a * b):\")\n",
    "print(a * b)  # [[5, 12], [21, 32]]\n",
    "print()\n",
    "\n",
    "# Exponentiation\n",
    "print(\"Power (a ** 2):\")\n",
    "print(a ** 2)  # [[1, 4], [9, 16]]\n",
    "print()\n",
    "\n",
    "# Common functions\n",
    "print(\"Square root (torch.sqrt(a)):\")\n",
    "print(torch.sqrt(a))\n",
    "print()\n",
    "\n",
    "print(\"Exponential (torch.exp(a)):\")\n",
    "print(torch.exp(a))\n",
    "print()\n",
    "\n",
    "print(\"Natural log (torch.log(a)):\")\n",
    "print(torch.log(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place Operations\n",
    "\n",
    "Operations ending with `_` modify the tensor in-place (save memory but lose the original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(f\"Original x: {x}\")\n",
    "\n",
    "# Regular operation (creates new tensor)\n",
    "y = x.add(10)\n",
    "print(f\"After y = x.add(10):\")\n",
    "print(f\"  x: {x}\")  # Unchanged\n",
    "print(f\"  y: {y}\")  # New tensor\n",
    "print()\n",
    "\n",
    "# In-place operation (modifies existing tensor)\n",
    "x.add_(10)  # Note the underscore!\n",
    "print(f\"After x.add_(10):\")\n",
    "print(f\"  x: {x}\")  # Modified!\n",
    "\n",
    "# WARNING: In-place operations can break autograd (gradient computation)\n",
    "# Avoid them when training neural networks unless you know what you're doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Matrix Operations\n",
    "\n",
    "### Why Matrix Multiplication Is Everywhere\n",
    "\n",
    "Matrix multiplication is the **core operation** in neural networks. Every fully connected layer, every attention mechanism - they all use matrix multiplication.\n",
    "\n",
    "**Remember**: For matrix multiplication `A @ B`:\n",
    "- `A` has shape `(m, n)`\n",
    "- `B` has shape `(n, p)`\n",
    "- Result has shape `(m, p)`\n",
    "- The inner dimensions `(n)` must match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "A = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])  # Shape: (3, 2)\n",
    "\n",
    "B = torch.tensor([[7, 8, 9],\n",
    "                  [10, 11, 12]])  # Shape: (2, 3)\n",
    "\n",
    "# Three equivalent ways to multiply\n",
    "C1 = torch.mm(A, B)      # Function\n",
    "C2 = A.mm(B)             # Method\n",
    "C3 = A @ B               # Operator (most readable!)\n",
    "\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"C shape: {C1.shape}\")  # (3, 3)\n",
    "print(f\"\\nResult (A @ B):\\n{C1}\")\n",
    "\n",
    "# All three are identical\n",
    "print(f\"\\nAre they equal? {torch.equal(C1, C2) and torch.equal(C2, C3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch matrix multiplication (common in transformers!)\n",
    "# Scenario: You have multiple matrices and want to multiply them pairwise\n",
    "\n",
    "# Batch of 32 matrices, each 10x20\n",
    "batch_A = torch.randn(32, 10, 20)\n",
    "# Batch of 32 matrices, each 20x30\n",
    "batch_B = torch.randn(32, 20, 30)\n",
    "\n",
    "# Multiply each corresponding pair\n",
    "batch_C = torch.bmm(batch_A, batch_B)  # Shape: (32, 10, 30)\n",
    "# Or use @ operator (works for batched too!)\n",
    "batch_C2 = batch_A @ batch_B\n",
    "\n",
    "print(f\"Batch A shape: {batch_A.shape}\")\n",
    "print(f\"Batch B shape: {batch_B.shape}\")\n",
    "print(f\"Batch C shape: {batch_C.shape}\")\n",
    "print(f\"Are they equal? {torch.equal(batch_C, batch_C2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Reshaping Tensors\n",
    "\n",
    "### Why Reshape?\n",
    "\n",
    "Different neural network layers expect different shapes:\n",
    "- CNN layers: `(batch, channels, height, width)`\n",
    "- Fully connected layers: `(batch, features)`\n",
    "- Transformers: `(batch, sequence_length, embedding_dim)`\n",
    "\n",
    "You'll constantly need to reshape data to fit these expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original tensor\n",
    "x = torch.arange(12)  # [0, 1, 2, ..., 11]\n",
    "print(f\"Original shape: {x.shape}\")  # torch.Size([12])\n",
    "print(f\"Original:\\n{x}\")\n",
    "print()\n",
    "\n",
    "# Reshape to 2D\n",
    "x_2d = x.reshape(3, 4)  # 3 rows, 4 columns\n",
    "print(f\"Reshaped to (3, 4):\\n{x_2d}\")\n",
    "print()\n",
    "\n",
    "# Reshape to 3D\n",
    "x_3d = x.reshape(2, 2, 3)  # 2 blocks of 2x3\n",
    "print(f\"Reshaped to (2, 2, 3):\\n{x_3d}\")\n",
    "print()\n",
    "\n",
    "# Use -1 to infer dimension (handy!)\n",
    "x_auto = x.reshape(3, -1)  # 3 rows, infer columns\n",
    "print(f\"Reshaped to (3, -1) -> actual shape: {x_auto.shape}\")\n",
    "print(x_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view() vs reshape() - what's the difference?\n",
    "# view() requires contiguous memory, reshape() doesn't\n",
    "# Always use reshape() unless you're optimizing for performance\n",
    "\n",
    "x = torch.arange(12)\n",
    "\n",
    "# Both work for contiguous tensors\n",
    "view_x = x.view(3, 4)\n",
    "reshape_x = x.reshape(3, 4)\n",
    "print(f\"Are they equal? {torch.equal(view_x, reshape_x)}\")\n",
    "\n",
    "# Flatten: Convert any shape to 1D\n",
    "flattened = x_3d.flatten()\n",
    "print(f\"\\nFlattened shape: {flattened.shape}\")  # torch.Size([12])\n",
    "print(f\"Flattened: {flattened}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze() and unsqueeze() - add/remove dimensions of size 1\n",
    "# Very useful for matching shapes in operations!\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(f\"Original shape: {x.shape}\")  # torch.Size([4])\n",
    "\n",
    "# Add dimension at position 0\n",
    "x_unsqueezed = x.unsqueeze(0)\n",
    "print(f\"After unsqueeze(0): {x_unsqueezed.shape}\")  # torch.Size([1, 4])\n",
    "\n",
    "# Add dimension at position 1\n",
    "x_unsqueezed2 = x.unsqueeze(1)\n",
    "print(f\"After unsqueeze(1): {x_unsqueezed2.shape}\")  # torch.Size([4, 1])\n",
    "\n",
    "# Remove dimensions of size 1\n",
    "x_squeezed = x_unsqueezed.squeeze()\n",
    "print(f\"After squeeze(): {x_squeezed.shape}\")  # torch.Size([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Broadcasting\n",
    "\n",
    "### What Is Broadcasting?\n",
    "\n",
    "Broadcasting is PyTorch's way of making tensors with different shapes compatible for operations.\n",
    "\n",
    "**Why is this powerful?** You can add a bias vector to every row of a matrix without explicit loops!\n",
    "\n",
    "**Rules**:\n",
    "1. If tensors have different number of dimensions, pad the smaller one with dimensions of size 1 on the left\n",
    "2. Dimensions are compatible if they're equal or one of them is 1\n",
    "3. The result has the maximum size along each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Add a scalar to a tensor\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "scalar = 10\n",
    "\n",
    "result = x + scalar  # scalar is broadcast to match x's shape\n",
    "print(f\"x + 10:\\n{result}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Add a vector to each row of a matrix\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "vector = torch.tensor([10, 20, 30])\n",
    "\n",
    "print(f\"Matrix shape: {matrix.shape}\")  # (3, 3)\n",
    "print(f\"Vector shape: {vector.shape}\")  # (3,)\n",
    "\n",
    "result = matrix + vector  # vector is broadcast to (3, 3)\n",
    "print(f\"\\nMatrix + vector:\\n{result}\")\n",
    "print()\n",
    "\n",
    "# What happened? \n",
    "# vector shape (3,) became (1, 3), then broadcast to (3, 3)\n",
    "# Each row of matrix gets the vector added to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: More complex broadcasting\n",
    "a = torch.ones(3, 1, 5)  # Shape: (3, 1, 5)\n",
    "b = torch.ones(1, 4, 5)  # Shape: (1, 4, 5)\n",
    "\n",
    "c = a + b  # Broadcasts to (3, 4, 5)\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"b shape: {b.shape}\")\n",
    "print(f\"c shape: {c.shape}\")  # (3, 4, 5)\n",
    "print()\n",
    "\n",
    "# How? \n",
    "# Dimension 0: 3 and 1 -> broadcast to 3\n",
    "# Dimension 1: 1 and 4 -> broadcast to 4  \n",
    "# Dimension 2: 5 and 5 -> stay 5\n",
    "\n",
    "# Example 4: Broadcasting error\n",
    "try:\n",
    "    x = torch.ones(3, 4)\n",
    "    y = torch.ones(2, 4)\n",
    "    z = x + y  # This will fail!\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Why? Dimension 0: 3 and 2 are incompatible (neither is 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Indexing and Slicing\n",
    "\n",
    "PyTorch indexing works just like NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "print()\n",
    "\n",
    "# Get single element\n",
    "print(f\"Element at [1, 2]: {x[1, 2]}\")  # 6\n",
    "print()\n",
    "\n",
    "# Get entire row\n",
    "print(f\"First row: {x[0]}\")  # [0, 1, 2, 3]\n",
    "print(f\"Last row: {x[-1]}\")  # [8, 9, 10, 11]\n",
    "print()\n",
    "\n",
    "# Get entire column\n",
    "print(f\"Second column: {x[:, 1]}\")  # [1, 5, 9]\n",
    "print()\n",
    "\n",
    "# Slicing (start:end:step)\n",
    "print(f\"First two rows:\\n{x[:2]}\")  # Rows 0 and 1\n",
    "print()\n",
    "print(f\"Last two columns:\\n{x[:, -2:]}\")  # Last 2 columns of all rows\n",
    "print()\n",
    "\n",
    "# Advanced indexing with boolean mask\n",
    "mask = x > 5\n",
    "print(f\"Mask (x > 5):\\n{mask}\")\n",
    "print(f\"Elements > 5: {x[mask]}\")  # Returns 1D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. GPU Acceleration\n",
    "\n",
    "### Why GPUs?\n",
    "\n",
    "GPUs can perform thousands of operations in parallel. For matrix operations (which neural networks are full of), this means **10-100x speedup**!\n",
    "\n",
    "**Key principle**: Keep your tensors on the same device. Don't mix CPU and GPU tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving tensors to GPU\n",
    "cpu_tensor = torch.randn(3, 3)\n",
    "print(f\"CPU tensor device: {cpu_tensor.device}\")\n",
    "\n",
    "# Method 1: Using .to()\n",
    "gpu_tensor = cpu_tensor.to(device)\n",
    "print(f\"GPU tensor device: {gpu_tensor.device}\")\n",
    "\n",
    "# Method 2: Using .cuda() (only if you're sure GPU exists)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor2 = cpu_tensor.cuda()\n",
    "    print(f\"GPU tensor2 device: {gpu_tensor2.device}\")\n",
    "\n",
    "# Creating tensors directly on GPU\n",
    "gpu_tensor3 = torch.randn(3, 3, device=device)\n",
    "print(f\"GPU tensor3 device: {gpu_tensor3.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison (only meaningful with GPU)\n",
    "import time\n",
    "\n",
    "size = 5000\n",
    "\n",
    "# CPU operation\n",
    "cpu_a = torch.randn(size, size)\n",
    "cpu_b = torch.randn(size, size)\n",
    "\n",
    "start = time.time()\n",
    "cpu_c = cpu_a @ cpu_b\n",
    "cpu_time = time.time() - start\n",
    "print(f\"CPU time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "# GPU operation (if available)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_a = cpu_a.to(device)\n",
    "    gpu_b = cpu_b.to(device)\n",
    "    \n",
    "    # Warm up GPU\n",
    "    _ = gpu_a @ gpu_b\n",
    "    torch.cuda.synchronize()  # Wait for GPU to finish\n",
    "    \n",
    "    start = time.time()\n",
    "    gpu_c = gpu_a @ gpu_b\n",
    "    torch.cuda.synchronize()\n",
    "    gpu_time = time.time() - start\n",
    "    \n",
    "    print(f\"GPU time: {gpu_time:.4f} seconds\")\n",
    "    print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "else:\n",
    "    print(\"GPU not available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Aggregation Operations\n",
    "\n",
    "These operations reduce tensors along dimensions - crucial for loss functions, metrics, and attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [4.0, 5.0, 6.0],\n",
    "                  [7.0, 8.0, 9.0]])\n",
    "\n",
    "print(f\"Original tensor:\\n{x}\\n\")\n",
    "\n",
    "# Sum\n",
    "print(f\"Sum of all elements: {x.sum()}\")  # Scalar\n",
    "print(f\"Sum along rows (dim=0): {x.sum(dim=0)}\")  # Sum each column\n",
    "print(f\"Sum along columns (dim=1): {x.sum(dim=1)}\")  # Sum each row\n",
    "print()\n",
    "\n",
    "# Mean\n",
    "print(f\"Mean: {x.mean()}\")\n",
    "print(f\"Mean along rows: {x.mean(dim=0)}\")\n",
    "print(f\"Mean along columns: {x.mean(dim=1)}\")\n",
    "print()\n",
    "\n",
    "# Max and min\n",
    "print(f\"Max value: {x.max()}\")\n",
    "print(f\"Max along rows: {x.max(dim=0)}\")  # Returns (values, indices)\n",
    "print(f\"Max values along rows: {x.max(dim=0).values}\")\n",
    "print(f\"Max indices along rows: {x.max(dim=0).indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Practical Example: Image Batch\n",
    "\n",
    "Let's work with a realistic scenario: a batch of images for a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a batch of RGB images\n",
    "# Shape: (batch_size, channels, height, width)\n",
    "batch_size = 32\n",
    "channels = 3  # RGB\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "# Create random images (normally you'd load real images)\n",
    "images = torch.randn(batch_size, channels, height, width)\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Total pixels: {images.numel():,}\")\n",
    "print(f\"Memory (float32): {images.numel() * 4 / 1e6:.2f} MB\")\n",
    "print()\n",
    "\n",
    "# Common operations\n",
    "# 1. Normalize images (subtract mean, divide by std)\n",
    "mean = images.mean(dim=(2, 3), keepdim=True)  # Mean per image per channel\n",
    "std = images.std(dim=(2, 3), keepdim=True)\n",
    "normalized = (images - mean) / (std + 1e-7)  # Add epsilon to avoid division by zero\n",
    "\n",
    "print(f\"Original mean: {images.mean():.4f}, std: {images.std():.4f}\")\n",
    "print(f\"Normalized mean: {normalized.mean():.4f}, std: {normalized.std():.4f}\")\n",
    "print()\n",
    "\n",
    "# 2. Get a single image from batch\n",
    "single_image = images[0]  # Shape: (3, 224, 224)\n",
    "print(f\"Single image shape: {single_image.shape}\")\n",
    "print()\n",
    "\n",
    "# 3. Convert to grayscale (average across channels)\n",
    "grayscale = images.mean(dim=1, keepdim=True)  # Shape: (32, 1, 224, 224)\n",
    "print(f\"Grayscale shape: {grayscale.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mini Exercises\n",
    "\n",
    "Try these exercises to test your understanding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Create and Manipulate Tensors\n",
    "\n",
    "Create a tensor of shape `(4, 5)` filled with random values from a normal distribution. Then:\n",
    "1. Calculate the mean and standard deviation\n",
    "2. Replace all values less than 0 with 0 (ReLU activation!)\n",
    "3. Calculate the sum of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "x = torch.randn(4, 5)\n",
    "print(f\"Original tensor:\\n{x}\\n\")\n",
    "\n",
    "# 1. Mean and std\n",
    "print(f\"Mean: {x.mean():.4f}\")\n",
    "print(f\"Std: {x.std():.4f}\\n\")\n",
    "\n",
    "# 2. ReLU (replace negative values with 0)\n",
    "x_relu = torch.where(x < 0, torch.tensor(0.0), x)\n",
    "# Or simpler: x_relu = torch.clamp(x, min=0)\n",
    "# Or even simpler: x_relu = torch.relu(x)\n",
    "print(f\"After ReLU:\\n{x_relu}\\n\")\n",
    "\n",
    "# 3. Sum of each row\n",
    "row_sums = x_relu.sum(dim=1)\n",
    "print(f\"Row sums: {row_sums}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Matrix Operations\n",
    "\n",
    "Given matrices A `(3, 4)` and B `(4, 2)`:\n",
    "1. Compute C = A @ B\n",
    "2. Verify the shape is correct\n",
    "3. Compute the transpose of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 2)\n",
    "\n",
    "# 1. Matrix multiplication\n",
    "C = A @ B\n",
    "\n",
    "# 2. Verify shape\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"C shape: {C.shape}\")  # Should be (3, 2)\n",
    "assert C.shape == (3, 2), \"Shape mismatch!\"\n",
    "print()\n",
    "\n",
    "# 3. Transpose\n",
    "C_T = C.T  # Or C.transpose(0, 1)\n",
    "print(f\"C:\\n{C}\\n\")\n",
    "print(f\"C transposed:\\n{C_T}\")\n",
    "print(f\"C_T shape: {C_T.shape}\")  # (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Broadcasting Challenge\n",
    "\n",
    "You have:\n",
    "- A batch of 16 vectors, each of size 128: shape `(16, 128)`\n",
    "- A bias vector of size 128: shape `(128,)`\n",
    "\n",
    "Add the bias to each vector in the batch using broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "batch = torch.randn(16, 128)\n",
    "bias = torch.randn(128)\n",
    "\n",
    "# Simply add! Broadcasting handles it\n",
    "result = batch + bias\n",
    "\n",
    "print(f\"Batch shape: {batch.shape}\")\n",
    "print(f\"Bias shape: {bias.shape}\")\n",
    "print(f\"Result shape: {result.shape}\")  # (16, 128)\n",
    "\n",
    "# Verify it worked: first row should be original + bias\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"First 3 elements of first row: {batch[0, :3]}\")\n",
    "print(f\"First 3 elements of bias: {bias[:3]}\")\n",
    "print(f\"First 3 elements of result: {result[0, :3]}\")\n",
    "print(f\"Are they equal? {torch.allclose(batch[0, :3] + bias[:3], result[0, :3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comprehensive Exercise: Simulated Linear Layer\n",
    "\n",
    "Implement a simple linear transformation (the core of fully connected layers):\n",
    "\n",
    "**Formula**: `y = xW + b`\n",
    "\n",
    "Where:\n",
    "- `x`: input batch of shape `(batch_size, input_features)`\n",
    "- `W`: weight matrix of shape `(input_features, output_features)`\n",
    "- `b`: bias vector of shape `(output_features,)`\n",
    "- `y`: output of shape `(batch_size, output_features)`\n",
    "\n",
    "**Tasks**:\n",
    "1. Create random tensors for x, W, and b with appropriate shapes\n",
    "2. Compute y\n",
    "3. Verify the output shape is correct\n",
    "4. Move everything to GPU (if available) and repeat\n",
    "\n",
    "Use: `batch_size=32`, `input_features=128`, `output_features=64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "input_features = 128\n",
    "output_features = 64\n",
    "\n",
    "# 1. Create tensors\n",
    "x = torch.randn(batch_size, input_features)\n",
    "W = torch.randn(input_features, output_features)  # Note: features are transposed!\n",
    "b = torch.randn(output_features)\n",
    "\n",
    "print(f\"x shape: {x.shape}\")  # (32, 128)\n",
    "print(f\"W shape: {W.shape}\")  # (128, 64)\n",
    "print(f\"b shape: {b.shape}\")  # (64,)\n",
    "print()\n",
    "\n",
    "# 2. Compute y = xW + b\n",
    "y = x @ W + b  # Broadcasting adds b to each row\n",
    "\n",
    "# 3. Verify shape\n",
    "print(f\"y shape: {y.shape}\")  # (32, 64)\n",
    "assert y.shape == (batch_size, output_features), \"Shape mismatch!\"\n",
    "print(\"Shape is correct!\\n\")\n",
    "\n",
    "# 4. GPU version\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move to GPU\n",
    "x_gpu = x.to(device)\n",
    "W_gpu = W.to(device)\n",
    "b_gpu = b.to(device)\n",
    "\n",
    "# Compute on GPU\n",
    "y_gpu = x_gpu @ W_gpu + b_gpu\n",
    "\n",
    "print(f\"y_gpu shape: {y_gpu.shape}\")\n",
    "print(f\"y_gpu device: {y_gpu.device}\")\n",
    "\n",
    "# Verify results are the same (within floating point precision)\n",
    "y_cpu_from_gpu = y_gpu.cpu()\n",
    "print(f\"\\nResults match: {torch.allclose(y, y_cpu_from_gpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Tensors are everywhere**: They're the fundamental data structure in PyTorch\n",
    "2. **Shape is king**: Most bugs come from shape mismatches. Always print shapes!\n",
    "3. **Broadcasting is powerful**: Lets you write concise code without explicit loops\n",
    "4. **GPU acceleration is easy**: Just move tensors with `.to(device)`\n",
    "5. **Matrix multiplication is the core operation**: `@` operator is your friend\n",
    "6. **PyTorch = NumPy + Deep Learning**: Similar API, but with gradients and GPUs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand tensors, you're ready to learn about **automatic differentiation** - the magic that makes neural network training possible!\n",
    "\n",
    "Continue to: [Topic 2: Automatic Differentiation & Backpropagation](02_autograd_backprop.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [PyTorch Tensor Documentation](https://pytorch.org/docs/stable/tensors.html)\n",
    "- [Broadcasting Semantics](https://pytorch.org/docs/stable/notes/broadcasting.html)\n",
    "- [CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
