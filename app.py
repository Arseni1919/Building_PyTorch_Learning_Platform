"""
PyTorch Learning Platform - Home Page (Streamlit)
"""

import streamlit as st

# Page config
st.set_page_config(
    page_title="PyTorch Learning Platform",
    page_icon="ğŸ”¥",
    layout="wide"
)

# Title
st.title("ğŸ”¥ PyTorch Learning Platform")
st.markdown("### Master PyTorch from Basics to Advanced Transformers")

st.markdown("---")

# Introduction
st.markdown("""
Master PyTorch from basics to advanced transformer architectures. This platform focuses on **understanding WHY** each concept exists and **HOW** it connects to modern LLMs.

**Use the sidebar** â†’ to navigate to any topic!
""")

st.markdown("---")

# Basic Level
st.markdown("## ğŸ“š Basic Level - Foundation Concepts")
st.markdown("""
1. **Introduction to PyTorch & Tensors** ğŸ”¢
2. **Autograd & Backpropagation** ğŸ”„
3. **Building Neural Networks (nn.Module)** ğŸ§ 
4. **Loss Functions & Optimizers** ğŸ¯
5. **Training Your First Model** ğŸš€
6. **Evaluation & Metrics** âœ…
""")

st.markdown("---")

# Intermediate Level
st.markdown("## ğŸ§  Intermediate Level - Practical Deep Learning")
st.markdown("""
7. Custom Datasets & DataLoaders ğŸ“‚
8. Convolutional Neural Networks (CNNs) ğŸ–¼ï¸
9. Batch Normalization & Dropout ğŸ”§
10. Transfer Learning ğŸ”„
11. Advanced Optimizers & Schedulers ğŸ“ˆ
12. Model Saving & Checkpointing ğŸ’¾
13. Introduction to Embeddings ğŸ”¤
""")

st.markdown("---")

# Advanced Level
st.markdown("## âš¡ Advanced Level - Transformer Architectures & Modern LLMs")
st.markdown("**The heart of modern AI! Deep dive into transformers:**")
st.markdown("""
14. Attention Mechanism from Scratch ğŸ¯
15. Multi-Head Attention ğŸ§©
16. Positional Encoding ğŸ“
17. RoPE (Rotary Position Embeddings) ğŸ”„
18. The Transformer Architecture ğŸ—ï¸
19. Modern Transformer Components (RMSNorm, SwiGLU) âš¡
20. Grouped Query Attention (GQA) ğŸ”
21. Flash Attention âš¡
22. KV Cache & Efficient Inference ğŸ’¨
23. Mixture of Experts (MoE) ğŸ“
""")

st.markdown("---")

# Professional Level
st.markdown("## ğŸš€ Professional Level - Production & Optimization")
st.markdown("""
24. Production-Ready Training Loop ğŸ”„
25. Model Optimization & Quantization ğŸ“Š
26. Distributed Training Concepts ğŸŒ
27. PyTorch Best Practices ğŸ“‹
28. Debugging & Profiling ğŸ”
29. Deployment Strategies ğŸš€
""")

st.markdown("---")

# What makes it special
st.markdown("## ğŸ’¡ What Makes This Platform Special?")
st.markdown("""
- **Transformer-Focused**: 10 dedicated topics on attention mechanisms and modern LLM architectures
- **Conceptual Connections**: Understand how concepts relate to each other
- **Hands-On Projects**: Build real projects at the end of each level
- **CPU-Friendly**: All examples run on CPU (no GPU needed!)
- **Simple Language**: Clear explanations of complex topics
- **Interactive Quizzes**: Test your understanding with each topic
""")

st.markdown("---")

# Projects
st.markdown("## ğŸ¯ Projects")
st.markdown("""
After completing each level, build a hands-on project:

- **ğŸ“š Basic**: Fashion-MNIST Classifier
- **ğŸ§  Intermediate**: Custom Dataset Trainer with Augmentation
- **âš¡ Advanced**: Mini-Transformer for Text Classification
- **ğŸš€ Professional**: Production Training Pipeline
""")

st.markdown("---")

# Get started
st.info("ğŸ‘ˆ **Select a topic from the sidebar to begin your learning journey!**")

# Footer
st.markdown("---")
st.markdown("**Built with â¤ï¸ using Streamlit** | Focus on Transformers & Modern LLM Architectures")
